% This text is proprietary.
% It's a part of presentation made by myself.
% It may not used commercial.
% The noncommercial use such as private and study is free
% Sep. 2005
% Author: Sascha Frank
% University Freiburg
% www.informatik.uni-freiburg.de/~frank/


\documentclass{beamer}
%% \usetheme{Warsaw}

\usepackage{color}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\setbeamertemplate{navigation symbols}{}
\setbeamerfont{page number in head/foot}{size=\normalsize}
\setbeamertemplate{footline}[frame number]
\usetikzlibrary{positioning}
%% \AtBeginSubsection{\frame{\subsectionpage}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
%% \DeclareMathOperator*{\argmin}{arg\,min}
%% \setbeamertemplate{caption}{\raggedright\insertcaption\par}
\captionsetup[figure]{labelformat=empty}% redefines the caption setup of the figures environment in the beamer class.
\captionsetup[subfigure]{labelformat=empty}% redefines the caption setup of the figures environment in the beamer class.

\defbeamertemplate{section page}{mine}[1][]{%
  \begin{centering}
    {\usebeamerfont{section name}\usebeamercolor[fg]{section name}#1}
    \vskip1em\par
    \begin{beamercolorbox}[sep=12pt,center]{part title}
      \usebeamerfont{section title}\insertsection\par
    \end{beamercolorbox}
  \end{centering}
}

\defbeamertemplate{section page}{mine2}[1][]{%
  \begin{centering}
    {\usebeamerfont{section name}\usebeamercolor[fg]{section name}#1}
    \vskip1em\par
    \begin{beamercolorbox}[sep=12pt,center]{part title}
      \usebeamerfont{section title}\insertsection\par
    \end{beamercolorbox}
  \end{centering}
  \vspace{2cm}
         {\small Transactions on Robotics (T-RO) 2012\\
           International Journal of Computer Vision (IJCV) 2014}
}

\setbeamertemplate{section page}[mine]



\newcommand*\nodestatecolor{green}
\newcommand*\scalefilter{0.7}
\newcommand*\initialstatetext{Previous State}
\newcommand*\initialstatecolor{yellow}

\tikzstyle{input}=[draw,fill=yellow,minimum width=2.6cm,thin]
\tikzstyle{method}=[draw,fill=pink,minimum width=1.8cm]
\tikzstyle{arr}=[-latex,ultra thick]
\tikzstyle{dummy}=[minimum width=2.6cm]


\title{Absolute scale velocity determination
combining visual and inertial
measurements for micro aerial
vehicles}
\subtitle{}
\date{June 24, 2015}
\author[Jacques Kaiser]{Jacques Kaiser\\{\small Supervised by Dr. Agostino Martinelli}}
 \institute{INRIA\\[\medskipamount]
      \includegraphics[width=0.18\textwidth]{images/logoUJF.jpg} \hspace{1.5cm}
      \includegraphics[width=0.18\textwidth]{images/logoINRIA.jpg} \hspace{1.5cm}
      \includegraphics[width=0.18\textwidth]{images/logoINP.png}
 }
 %% \institute{INRIA}
 %% \titlegraphic{\includegraphics[width=\textwidth,height=.5\textheight]{someimage}}

\begin{document}

\maketitle

\section{Sensor fusion}

\AtBeginSection{\frame{\sectionpage}}

\begin{frame}{Micro aerial vehicles}
  \begin{columns}[T]
    \column{.7\textwidth}
    \centering
    \includegraphics<1,5>[width=0.6\textwidth]{images/drone.png}
    \includegraphics<2>[width=0.6\textwidth]{images/droneMapping.png}
    \includegraphics<3>[width=0.6\textwidth]{images/droneRescue.png}
    \includegraphics<4>[width=0.6\textwidth]{images/droneFireIndoor.png}
    \includegraphics<6->[width=0.6\textwidth]{images/droneState.png}
    %% \includegraphics<3->[width=0.6\textwidth]{images/dronePointState.png}
    \hspace{-2cm}
    \column<7->{.3\textwidth}
    \begin{flushleft}
    \small
    A basic state vector:

    \[
    X =\left[\begin{array}{c}position \\ velocity \\ orientation\end{array}\right]
    \]
    \end{flushleft}
  \end{columns}

\onslide<5->
\vspace{2em}
\textbf{Localization} in \textbf{various environments}

\onslide<8->
\vspace{2em}
The goal of sensor fusion for state estimation is to \textbf{recover $X$}
\end{frame}

\subsection{Filter based fusion}

\begin{frame}{Visual-inertial sensor fusion}

{\centering
\textbf{Filter based method}

\only<2->{\renewcommand*\nodestatecolor{yellow}}
%% \only<2->{\renewcommand*\scalefilter{0.7}}
\only<4->{\renewcommand*\initialstatecolor{blue!60}}
\only<4->{\renewcommand*\initialstatetext{Initial State}}

\begin{tikzpicture}[scale=\scalefilter, every node/.style={transform shape}]
\path [draw=none, use as bounding box] (0,0) rectangle (17,4);

\node (A) at (1,3) [input, fill=\initialstatecolor] {\initialstatetext};
\node (dummy1) [dummy, below=2mm of A] {};
\node (C) [input,below=2mm of dummy1] {Measurements};
\node (D) [method,right=of dummy1] {Fusion};
\node (E) [input, right=of D, fill=\nodestatecolor] {State};

\node<2-> (dummy2) [dummy, below=2mm of E] {};
\node<2-> (F) [input, below=2mm of dummy2] {Measurements};


\node<3-> (G) [method, right=of dummy2] {Fusion};
\node<3-> (H) [input, right=of G, fill=green] {State};

\draw[arr] (A.east) -- (D.175);
\draw[arr] (C.east) -- (D.185);
\draw[arr] (D.east) -- (E.west);
\draw<3->[arr] (E.east) -- (G.175);
\draw<3->[arr] (F.east) -- (G.185);
\draw<3->[arr] (G.east) -- (H.west);

\end{tikzpicture}
}

\onslide<4->
How to recover the \textbf{initial state}?

\onslide<5->
We need a \textbf{deterministic solution}

\vspace{0.5cm}
{\centering
\begin{tikzpicture}
\tikzstyle{input}=[draw,fill=yellow,minimum width=3cm,thin]
\tikzstyle{method}=[draw,fill=pink,minimum width=2cm]
\tikzstyle{every path}=[-latex,ultra thick]
\node (C) [input] {Measurements};
\node (D) [method,right=of C] {Fusion};
\node (E) [input, right=of D, fill=green] {State};



\draw (C.east) -- (D.west);
\draw (D.east) -- (E.west);
\end{tikzpicture}
}

\end{frame}

\subsection{Deterministic solution}

\begin{frame}{Deterministic solutions in Computer Vision}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{images/directMethod.png}
\end{figure}

%% \onslide<2->
%% \begin{itemize}
%% \item 8-point algorithm;
%% \item sparse model-based image alignment;
%% \item ...
%% \end{itemize}

\onslide<2->

{\small
  But the relative \textbf{translation} and \textbf{distance to features} are recovered only \textbf{up to scale}
}

% Camera is an angle sensor
\end{frame}

\subsection{Absolute scale}

{ % all template changes are local to this group.
    \setbeamertemplate{navigation symbols}{}
    \begin{frame}[plain]{Absolute scale from visual measurements}
      How big is this building?
      \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingDetour.png}\end{center}
     \end{frame}
}
{ % all template changes are local to this group.
    \setbeamertemplate{navigation symbols}{}
    \begin{frame}[plain]{Absolute scale from visual measurements}
      \vspace{0.9em}
      \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingScale.jpg}\end{center}
     \end{frame}
}


%% \begin{frame}{Absolute scale from visual measurements}
%%   How big is this building?
%%   \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingDetour.png}\end{center}

%% \end{frame}

%% % we can tell the central door is bigger than the people
%% % but now way to determine physical quantities: how big, how far, how fast is the camera moving,..
%% % Even provided with many images
%% %

%% \begin{frame}{Absolute scale from visual measurements}
%%   \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingScale.jpg}\end{center}
%% \end{frame}
%% % We need to known a physical quantity to set the absolute scale
%% % That's how drones are initialized..


\begin{frame}{Methods to recover the absolute scale}

  \begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
      \includegraphics[width=\textwidth]{images/referenceInEnv.png}
      \onslide<4->{
        \caption{Not suited to unknown environments}
      }
    \end{subfigure}
    \onslide<2->{
      \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/altitudeSensor.png}
      \onslide<4->{
        \caption{Not precise, works only in hover}
      }
      \end{subfigure}
    }
    \onslide<3->{
      \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{images/gpsSensor.png}
      \onslide<4->{
        \caption{Does not work in GPS denied environments}
      }
      \end{subfigure}
    }
  \end{figure}
\end{frame}

% so far we only considered visual measurements
% the IMU provides physical quantity (m/s^2 and rad/s)
\begin{frame}{Inertial Measurement Unit (IMU)}

The IMU consists of two sensors providing \textbf{physical quantities}:
\begin{itemize}
\item Accelerometer: linear acceleration (and gravity) ($m/s^2$);
\item Gyroscope: angular velocity ($rad/s$).
\end{itemize}

\end{frame}

\begin{frame}{Back to the title}
  \textcolor<4->{green}{Absolute scale velocity} \textcolor<3->{pink}{determination} combining \textcolor<2->{yellow}{visual and inertial measurements} for micro aerial vehicles

  \vspace{1em}


  \onslide<2->


  {\centering
    \begin{tikzpicture}[scale=\scalefilter, every node/.style={transform shape}]
      \node (A) [input, fill=yellow] {Measurements};
      \node (B) [above=2mm of A] {Visual};
      \node (C) [below=2mm of A] {Inertial};
      \node<3-> (D) [method,right=of A] {Fusion};
      \node<4-> (E) [input, right=of D, fill=\nodestatecolor] {State (Absolute scale)};
      \draw<3->[arr] (A.east) -- (D.west);
      \draw<4->[arr] (D.east) -- (E.west);
    \end{tikzpicture}
  }

\end{frame}
% \begin{frame}{Dead reckoning}
% Provided only with inertial measurements, we are subject to drift.

% %bias ?
% \end{frame}

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents
\end{frame}


\setbeamertemplate{section page}[mine2]

\section{The closed-form solution}

% So far, knowledge of previous state was required. Now we have a Closed-form solution that only relies on measurements over a short interval of time
\begin{frame}{The Closed-Form Solution}

Requires:
\begin{itemize}
\item \textcolor<3->{blue}{Calibrated camera};
\item \textcolor<3->{blue}{Inertial Measurement Unit (IMU)};
\item \textcolor<3->{blue}{External Camera IMU transformation}.
\end{itemize}

Output:
\begin{itemize}
\item \textcolor<3->{red}{Initial velocity};
\item \textcolor<3->{red}{Distance to point-features};
\item \textcolor<3->{red}{Attitude}.
\end{itemize}

\onslide<2->
\[
\textcolor<3->{blue}{\Xi} \textcolor<3->{red}{X} = \textcolor<3->{blue}{S}
\]
\end{frame}

\begin{frame}{Test setup}
  \includegraphics<1>[width=\textwidth]{images/setupTestDrone.png}
  \includegraphics<2>[width=\textwidth]{images/setupTestDroneMotion.png}
  \includegraphics<3>[width=\textwidth]{images/setupTestDroneGT.png}
  \includegraphics<4>[width=\textwidth]{images/setupTestDroneFakeFeatures.png}
  \includegraphics<5>[width=\textwidth]{images/setupTestDroneSpeedGT.png}
  \includegraphics<6>[width=\textwidth]{images/setupTestDroneError.png}
  \includegraphics<7>[width=\textwidth]{images/setupTestDrone1s.png}
  \includegraphics<8>[width=\textwidth]{images/setupTestDrone3s.png}
\end{frame}

\begin{frame}{Problem: not robust in practice}
\emph{''\textbf{A closed-form solution} for state estimation with a visual-inertial system that does not require initialization was presented. However, this approach is \textbf{not suitable for systems that rely on noisy sensor data}''}\\
\rightline{{\rm --- Matthias Faessler, ICRA 2015}}

\begin{columns}
  \column<2->{.5\textwidth}
\begin{figure}[h!]
  \centering
  \resizebox{\textwidth}{!}{\input{graph/CF2}}
\end{figure}
\column<3->{.5\textwidth}
$50\%$ relative error on speed and distance estimation
\end{columns}
\end{frame}

\begin{frame}{Improving the performance}
  What makes the estimations so bad?

  \begin{block}{Possible bottlenecks}
    \begin{itemize}
    \item<1-> Motion;
    \item<2-> Observed features;
    \item<3-> Noisy sensors.
    %%   \begin{itemize}
    %%   \item Impact of \textcolor{blue}{bias} on performance;
    %%   \item Impact of \textcolor{green}{non systematic errors} on performance.
    %%   \end{itemize}
    \end{itemize}
  \end{block}

  \onslide<4->
  Sensors provide measurements affected by a Gaussian noise:

  \[
  N(\mu + \textcolor<2->{blue}{B}, \textcolor<2->{green}{\sigma^2})
  \]

  \onslide<5->
  We considered:
  \begin{itemize}
  \item \textcolor{blue}{Biased} accelerometer;
  \item \textcolor{blue}{Biased} gyroscope.
  \end{itemize}
\end{frame}


%% \begin{frame}{Numerical stability}
%%   \[
%%   \left[
%%     \begin{array}{lcl}
%%       S_j &=& \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j\\
%%       0_3 &=& \lambda_1^1\mu_1^1 - \lambda_j^1\mu_j^1 - \lambda_1^i\mu_1^i + \lambda^i_j \mu^i_j
%%     \end{array}
%%   \right.
%%   \]

%% \[
%% S_j = \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j
%% \]
%% \end{frame}
\subsection{Identifying performance bottlenecks}
\begin{frame}{Biased inertial measurements}

  \begin{center}
    \textbf{Speed estimation error}
  \end{center}

  \begin{columns}[T]
    \column{.5\textwidth}
    \begin{figure}[h!]
      \centering
      \resizebox{0.85\textwidth}{!}{\input{graph/accBiasSpeed}}
      \caption{Varying accelerometer bias}
    \end{figure}
    \column{.5\textwidth}
    \begin{figure}[h!]
      \centering
      \resizebox{0.85\textwidth}{!}{\input{graph/gyroBiasSpeed}}
      \caption{Varying gyroscope bias}
    \end{figure}

  \end{columns}
\end{frame}

\subsection{Estimating the gyroscope bias}
\begin{frame}{Estimating the gyroscope bias}

  \begin{itemize}[<+->]
  \item When solving  $\Xi X = S$, we are solving $\argmin_X ||\Xi X - S||^2$;
  \item Unfortunately, we can not express the gyroscope bias linearly;
  \item Alternative: non-linear minimization
    \[
    cost(B) = \argmin_X ||\Xi X - S||^2 \onslide<6->{\textcolor{blue}{+ \lambda \times |B|}}
    \]
  {\tiny With $B$ the gyroscope bias, $\Xi$ and $S$ computed with respect to $B$}
  \end{itemize}

  \onslide<4->
  \begin{figure}[h!]
    \centering
      \begin{subfigure}[b]{0.47\textwidth}
        \resizebox{\textwidth}{!}{\input{graph/costXZ2}}
        \onslide<5->{\caption{Symmetry induced by the strong weight of the gravity}}
      \end{subfigure}
      \onslide<6->{
      \begin{subfigure}[b]{0.47\textwidth}
        \resizebox{\textwidth}{!}{\input{graph/costXZReg}}
        \caption{With regularization $\lambda =3$}
      \end{subfigure}
      }
  \end{figure}

\end{frame}

\subsection{Validation}

\begin{frame}{Results}
  \begin{figure}[h!]
    \centering
    \textbf{Speed estimation error}\\
    \vspace{1em}

    \resizebox{0.5\textwidth}{!}{\input{graph/speed}}
  \end{figure}

  \onslide<2->
  Moreover, our technique:
  \begin{itemize}
    \item Does not require initialization;
    \item Provides the gyroscope bias.
  \end{itemize}

\end{frame}


\setbeamertemplate{section page}[mine]

\section{Conclusion}

\begin{frame}{Conclusion}

  \begin{enumerate}
  \item Closed-form solution for visual-inertial fusion;
    \begin{itemize}
      \item No initialization required;
      \item Recovers the absolute scale.
    \end{itemize}
  \item<2-> Does not work well in practice;
  \item<3-> Gyroscope bias is a performance bottleneck;
  \item<4-> \textbf{Method to estimate this bias};
  \item<5-> Works well in practice;
  \item<6-> Also provides the gyroscope bias.
  \end{enumerate}

\end{frame}

\begin{frame}{Future work}
  Implementation on a real platform
  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.6\textwidth]{images/drone.png}
  \end{figure}

\end{frame}

\begin{frame}[plain,c]
  \begin{center}
    Thank you for your attention,\\
    Any question?
  \end{center}
\end{frame}

% So far, knowledge of previous state was required. Now we have a Closed-form solution that only relies on measurements over a short interval of time
\begin{frame}[noframenumbering]{The Closed-Form Solution}

Requires:
\begin{itemize}
\item Calibrated camera;
\item Inertial Measurement Unit (IMU);
\item External Camera IMU transformation.
\end{itemize}

Output:
\begin{itemize}
\item \textcolor<3->{red}{Initial velocity};
\item \textcolor<3->{green}{Distance to point-features};
\item \textcolor<3->{blue}{Attitude}.
\end{itemize}

\onslide<2->

\[
S_j = \textcolor<3->{green}{\lambda_1^i}\mu_1^i - \textcolor<3->{red}{V} t_j - \textcolor<3->{blue}{G} \frac{t_j^2}{2} - \textcolor<3->{green}{\lambda^i_j} \mu^i_j
\]
\end{frame}

\subsection{Expression}
\begin{frame}[noframenumbering]{The Overconstrained Linear System}

  \[
  \textcolor<3->{green}{S_j} = \textcolor<3->{red}{\lambda_1^i}\textcolor<3->{blue}{\mu_1^i} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_j} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_j^2}{2}} - \textcolor<3->{red}{\lambda^i_j}\textcolor<3->{blue}{\mu^i_j}
  \]

  Valid for every point-feature $i$ at any time $t_j$:

  \onslide<2->
  \[
  \left[
    \begin{array}{c}
      \textcolor<3->{green}{S_2} = \textcolor<3->{red}{\lambda_1^1}\textcolor<3->{blue}{\mu_1^1} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_2} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_2^2}{2}} - \textcolor<3->{red}{\lambda^1_2}\textcolor<3->{blue}{\mu^1_2} \\
      \textcolor<3->{green}{S_2} = \textcolor<3->{red}{\lambda_1^2}\textcolor<3->{blue}{\mu_1^2} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_2} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_2^2}{2}} - \textcolor<3->{red}{\lambda^2_2}\textcolor<3->{blue}{\mu^2_2} \\
      \vdots \\
      \textcolor<3->{green}{S_3} = \textcolor<3->{red}{\lambda_1^1}\textcolor<3->{blue}{\mu_1^1} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_3} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_3^2}{2}} - \textcolor<3->{red}{\lambda^1_3}\textcolor<3->{blue}{\mu^1_3} \\
      \vdots \\
      \textcolor<3->{green}{S_N} = \textcolor<3->{red}{\lambda_1^{n_i}}\textcolor<3->{blue}{\mu_1^{n_i}} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_N} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_N^2}{2}} - \textcolor<3->{red}{\lambda^{n_i}_N}\textcolor<3->{blue}{\mu^{n_i}_N}
    \end{array}
    \right.
    \]

    \onslide<3->
    \[
    \textcolor{blue}{\Xi} \textcolor{red}{X} = \textcolor{green}{S}
    \]

\end{frame}

\begin{frame}[noframenumbering]{Gyroscope bias estimation}
  \begin{figure}[h!]
    \centering

    \begin{subfigure}[b]{0.78\textwidth}
      \caption{Optimized Closed-form solution}
      \resizebox{0.45\textwidth}{!}{\input{graph/opt30ftspeed}} ~
      \resizebox{0.45\textwidth}{!}{\input{graph/biasEstimation30Ft}}
    \end{subfigure}

    \begin{subfigure}[b]{0.35\textwidth}
      \caption{Original Closed-form solution}
      \resizebox{\textwidth}{!}{\input{graph/gyroBiasSpeed}}
    \end{subfigure}

  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{Numerical stability}

  \begin{columns}
    \begin{column}{.5\textwidth}
    {\small
    \[
    \left[
      \begin{array}{lcl}
        S_j &=& \lambda_1^1\mu_1^1 - V t_j - G \frac{t_j^2}{2} - \lambda^1_j \mu^1_j\\
        0_3 &=& \lambda_1^1\mu_1^1 - \lambda_j^1\mu_j^1 - \lambda_1^i\mu_1^i + \lambda^i_j \mu^i_j
      \end{array}
      \right.
      \]
    }
    \end{column}
    \vrule{}
    \begin{column}{.5\textwidth}
    {\small
    \[
    S_j = \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j
    \]
    }
    \end{column}
  \end{columns}

  \begin{figure}[h!]
    \centering
    \resizebox{0.5\textwidth}{!}{\input{graph/CF2vsCF3}}
  \end{figure}

\end{frame}

%% \begin{document}
%% \title{Simple Beamer Class}
%% \author{Sascha Frank}
%% \date{\today}

%% \frame{\titlepage}

%% \frame{\frametitle{Table of contents}\tableofcontents}



\end{document}
