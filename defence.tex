% This text is proprietary.
% It's a part of presentation made by myself.
% It may not used commercial.
% The noncommercial use such as private and study is free
% Sep. 2005
% Author: Sascha Frank
% University Freiburg
% www.informatik.uni-freiburg.de/~frank/


\documentclass{beamer}
%% \usetheme{Warsaw}

\usepackage{color}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\setbeamertemplate{navigation symbols}{}
\setbeamerfont{page number in head/foot}{size=\normalsize}
\setbeamertemplate{footline}[frame number]
\usetikzlibrary{positioning}
\AtBeginSection{\frame{\sectionpage}}
%% \AtBeginSubsection{\frame{\subsectionpage}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
%% \DeclareMathOperator*{\argmin}{arg\,min}



\newcommand*\nodestatecolor{green}
\newcommand*\scalefilter{1}
\newcommand*\initialstatetext{Previous State}
\newcommand*\initialstatecolor{yellow}

\tikzstyle{input}=[draw,fill=yellow,minimum width=2.6cm,thin]
\tikzstyle{method}=[draw,fill=pink,minimum width=1.8cm]
\tikzstyle{arr}=[-latex,ultra thick]
\tikzstyle{dummy}=[minimum width=2.6cm]


\title{Absolute scale velocity determination
combining visual and inertial
measurements for micro aerial
vehicles}
\subtitle{}
\date{June 24, 2015}
\author{Jacques Kaiser}
\institute{INRIA}

\begin{document}

\maketitle

\section{Sensor fusion}

\begin{frame}{Micro aerial vehicles}
\includegraphics<1>[width=0.6\textwidth]{images/drone.png}
\includegraphics<2>[width=0.6\textwidth]{images/droneState.png}
\includegraphics<3->[width=0.6\textwidth]{images/dronePointState.png}

\onslide<4->

%drone is a rigid body - you can reduce it to a point
\begin{columns}[T] % contents are top vertically aligned
\column{.5\textwidth}
\centering
A basic state vector:
\[
X =
\left[
\begin{array}{c}
r \\ \dot{r}\\ q
\end{array}
\right]
\]

\column{.5\textwidth}
        \begin{itemize}
        \item $r$ position;
        \item $\dot{r}$ velocity;
        \item $q$ orientation.
        \end{itemize}
\end{columns}

\onslide<5->
\textbf{The goal of sensor fusion is to recover the state $X$}

\end{frame}

\subsection{Filter based fusion}

\begin{frame}{Visual-inertial sensor fusion}

{\centering
\textbf{Filter based method}

\only<2->{\renewcommand*\nodestatecolor{yellow}}
\only<2->{\renewcommand*\scalefilter{0.7}}
\only<4->{\renewcommand*\initialstatecolor{blue!60}}
\only<4->{\renewcommand*\initialstatetext{Initial State}}

\begin{tikzpicture}[scale=\scalefilter, every node/.style={transform shape}]

\node (A) [input, fill=\initialstatecolor] {\initialstatetext};
\node (dummy1) [dummy, below=2mm of A] {};
\node (C) [input,below=2mm of dummy1] {Measurements};
\node (D) [method,right=of dummy1] {Fusion};
\node (E) [input, right=of D, fill=\nodestatecolor] {State};

\node<2-> (dummy2) [dummy, below=2mm of E] {};
\node<2-> (F) [input, below=2mm of dummy2] {Measurements};


\node<3-> (G) [method, right=of dummy2] {Fusion};
\node<3-> (H) [input, right=of G, fill=green] {State};

\draw[arr] (A.east) -- (D.175);
\draw[arr] (C.east) -- (D.185);
\draw[arr] (D.east) -- (E.west);
\draw<3->[arr] (E.east) -- (G.175);
\draw<3->[arr] (F.east) -- (G.185);
\draw<3->[arr] (G.east) -- (H.west);

\end{tikzpicture}
}

\onslide<4->
How to recover the \textbf{initial state}?

\onslide<5->
We need a \textbf{deterministic solution}

\vspace{0.5cm}
{\centering
\begin{tikzpicture}
\tikzstyle{input}=[draw,fill=yellow,minimum width=3cm,thin]
\tikzstyle{method}=[draw,fill=pink,minimum width=2cm]
\tikzstyle{every path}=[-latex,ultra thick]
\node (C) [input] {Measurements};
\node (D) [method,right=of C] {Fusion};
\node (E) [input, right=of D, fill=green] {State};



\draw (C.east) -- (D.west);
\draw (D.east) -- (E.west);
\end{tikzpicture}
}

\end{frame}

\subsection{Deterministic solution}

\begin{frame}{Deterministic solutions in Computer Vision}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{images/directMethod.png}
\end{figure}

\onslide<2->
\begin{itemize}
\item 8-point algorithm;
\item sparse model-based image alignment;
\item ...
\end{itemize}

\onslide<3->

But the relative translation and distance to features are recovered only \textbf{up to scale}

% Camera is an angle sensor
\end{frame}

\subsection{Absolute scale}

{ % all template changes are local to this group.
    \setbeamertemplate{navigation symbols}{}
    \begin{frame}[plain]{Absolute scale from visual measurements}
      How big is this building?
      \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingDetour.png}\end{center}
     \end{frame}
}
{ % all template changes are local to this group.
    \setbeamertemplate{navigation symbols}{}
    \begin{frame}[plain]{Absolute scale from visual measurements}
      \vspace{1.1em}
      \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingScale.jpg}\end{center}
     \end{frame}
}


%% \begin{frame}{Absolute scale from visual measurements}
%%   How big is this building?
%%   \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingDetour.png}\end{center}

%% \end{frame}

%% % we can tell the central door is bigger than the people
%% % but now way to determine physical quantities: how big, how far, how fast is the camera moving,..
%% % Even provided with many images
%% %

%% \begin{frame}{Absolute scale from visual measurements}
%%   \vspace{-2em}\begin{center}\includegraphics[width=\textwidth]{images/buildingScale.jpg}\end{center}
%% \end{frame}
%% % We need to known a physical quantity to set the absolute scale
%% % That's how drones are initialized..


\begin{frame}{Methods to recover the absolute scale}


  \includegraphics[width=0.45\textwidth]{images/referenceInEnv.png}~
  \includegraphics<2->[width=0.45\textwidth]{images/altitudeSensor.png}

  \begin{columns}[T] % contents are top vertically aligned
    \column<3->{.46\textwidth}
    \centering
    Not suited to unknown environments

    \column<3->{.5\textwidth}
    \centering
    Not precise, works only in hover

    %add column for GPS

\end{columns}

\end{frame}

% so far we only considered visual measurements
% the IMU provides physical quantity (m/s^2 and rad/s)
\begin{frame}{Inertial Measurement Unit (IMU)}

The IMU consists of two sensors providing \textbf{physical quantities}:
\begin{itemize}
\item Accelerometer: linear acceleration - gravity ($m/s^2$);
\item Gyroscope: angular velocity ($rad/s$).
\end{itemize}

\end{frame}

\begin{frame}{Title}
absolute scale velocity determination combining visual and inertial measurements for micro aerial vehicles
\end{frame}
% \begin{frame}{Dead reckoning}
% Provided only with inertial measurements, we are subject to drift.

% %bias ?
% \end{frame}

\begin{frame}
\frametitle{Table of Contents}
\tableofcontents
\end{frame}

\section{The closed-form solution}

% So far, knowledge of previous state was required. Now we have a Closed-form solution that only relies on measurements over a short interval of time
\begin{frame}{The Closed-Form Solution - 2014}

Requires:
\begin{itemize}
\item Camera;
\item IMU;
\item External Camera IMU transformation.
\end{itemize}

Output:
\begin{itemize}
\item \alert<2->{Initial velocity};
\item \alert<2->{Distance to point-features};
\item Attitude.
\end{itemize}

\onslide<3->

\[
S_j = \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j
\]
\end{frame}

\subsection{Linear system}
\begin{frame}{The Overconstrained Linear System}

  \[
  \textcolor<3->{green}{S_j} = \textcolor<3->{red}{\lambda_1^i}\textcolor<3->{blue}{\mu_1^i} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_j} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_j^2}{2}} - \textcolor<3->{red}{\lambda^i_j}\textcolor<3->{blue}{\mu^i_j}
  \]

  Valid for every point-features $i$ at any time $t_j$:

  \onslide<2->
  \[
  \left[
    \begin{array}{c}
      \textcolor<3->{green}{S_2} = \textcolor<3->{red}{\lambda_1^1}\textcolor<3->{blue}{\mu_1^1} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_2} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_2^2}{2}} - \textcolor<3->{red}{\lambda^1_2}\textcolor<3->{blue}{\mu^1_2} \\
      \textcolor<3->{green}{S_2} = \textcolor<3->{red}{\lambda_1^2}\textcolor<3->{blue}{\mu_1^2} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_2} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_2^2}{2}} - \textcolor<3->{red}{\lambda^2_2}\textcolor<3->{blue}{\mu^2_2} \\
      \vdots \\
      \textcolor<3->{green}{S_3} = \textcolor<3->{red}{\lambda_1^1}\textcolor<3->{blue}{\mu_1^1} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_3} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_3^2}{2}} - \textcolor<3->{red}{\lambda^1_3}\textcolor<3->{blue}{\mu^1_3} \\
      \vdots \\
      \textcolor<3->{green}{S_N} = \textcolor<3->{red}{\lambda_1^{n_i}}\textcolor<3->{blue}{\mu_1^{n_i}} - \textcolor<3->{red}{V}\textcolor<3->{blue}{t_N} - \textcolor<3->{red}{G} \textcolor<3->{blue}{\frac{t_N^2}{2}} - \textcolor<3->{red}{\lambda^{n_i}_N}\textcolor<3->{blue}{\mu^{n_i}_N}
    \end{array}
    \right.
    \]

    \onslide<3->
    \[
    \textcolor{blue}{\Xi} \textcolor{red}{X} = \textcolor{green}{S}
    \]

\end{frame}


\begin{frame}{Problem: not robust in practice}
\emph{''\textbf{A closed-form solution} for state estimation with a visual-inertial system that does not require initialization was presented. However, this approach is \textbf{not suitable for systems that rely on noisy sensor data}''}\\
\rightline{{\rm --- Matthias Faessler, ICRA 2015}}

\begin{columns}
  \column<2->{.5\textwidth}
\begin{figure}[h!]
  \centering
  \resizebox{\textwidth}{!}{\input{graph/CF2}}
\end{figure}
\column<3->{.5\textwidth}
$50\%$ relative error on speed and distance estimation
\end{columns}
\end{frame}

\begin{frame}{Improving the performance}
  What makes the estimations so bad?

  \onslide<2->
  Sensors provide measurements affected by a Gaussian noise:

  \[
  N(\mu + \textcolor<3->{blue}{B}, \textcolor<3->{green}{\sigma^2})
  \]

  \begin{block}{Possible bottlenecks}
    For all sensors:
    \begin{itemize}
    \item Impact of \textcolor{blue}{bias} on performance;
    \item Impact of \textcolor{green}{non systematic errors} on performance.
    \end{itemize}
  \end{block}
\end{frame}


%% \begin{frame}{Numerical stability}
%%   \[
%%   \left[
%%     \begin{array}{lcl}
%%       S_j &=& \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j\\
%%       0_3 &=& \lambda_1^1\mu_1^1 - \lambda_j^1\mu_j^1 - \lambda_1^i\mu_1^i + \lambda^i_j \mu^i_j
%%     \end{array}
%%   \right.
%%   \]

%% \[
%% S_j = \lambda_1^i\mu_1^i - V t_j - G \frac{t_j^2}{2} - \lambda^i_j \mu^i_j
%% \]
%% \end{frame}
\subsection{Impact of Accelerometer bias on performance}
\begin{frame}{Accelerometer bias}
  \begin{columns}
    In dead reckoning task:
    \column{.4\textwidth}
    \begin{figure}[h!]
      \centering
      \resizebox{\textwidth}{!}{\input{graph/deadReckoningGT}}
    \end{figure}
    \begin{figure}[h!]
      \centering
      \resizebox{\textwidth}{!}{\input{graph/deadReckoningAccBias}}
    \end{figure}
    \column{.3\textwidth}
    In the closed-form solution:

  \end{columns}
\end{frame}

\subsection{Impact of Gyroscope bias on performance}
\begin{frame}{Gyroscope bias}
  \begin{columns}
    In dead reckoning task:
    \column{.4\textwidth}


    \begin{figure}[h!]
      \centering
      \resizebox{0.7\textwidth}{!}{\input{graph/deadReckoningGT}}
    \end{figure}
    \begin{figure}[h!]
      \centering
      \resizebox{0.7\textwidth}{!}{\input{graph/deadReckoningGyroBias}}
    \end{figure}
    \column{.5\textwidth}
    In the closed-form solution:

  \end{columns}
\end{frame}

\begin{frame}{Estimating the gyroscope bias}

  \begin{itemize}[<+->]
  \item When solving  $\Xi X = S$, we are solving $\argmin_X ||\Xi X - S||^2$;
  \item Unfortunately, We can not express the gyroscope bias linearly;
  \item Alternative: non-linear minimization
  \[
  \argmin_{B,X} ||\Xi X - S||^2
  \]
  With $B$ the gyroscope bias, $\Xi$ and $S$ computed with respect to $B$
  \end{itemize}

  \onslide<3->
  \begin{figure}[h!]
        \centering
        \resizebox{0.47\textwidth}{!}{\input{graph/costXZ2}}
  \end{figure}

  \onslide<4->
  Symmetry induced by the strong weight of the gravity
\end{frame}

\begin{frame}{Getting rid of the symmetry}

  We introduce a regularization paremeter $\lambda$:

  \[
  \argmin_{B,X} ||\Xi X - S||^2 + $\lambda$ \times B^2
  \]

  \onslide<2->
  \begin{columns}
    \column{.4\textwidth}
    \begin{figure}[h!]
      \centering
      \resizebox{\textwidth}{!}{\input{graph/costXZ}}
      \caption{No regularization}
    \end{figure}~

    \column{.4\textwidth}
    \begin{figure}[h!]
      \centering
      \resizebox{\textwidth}{!}{\input{graph/costXZReg}}
      \caption{With regularization $\lambda=3$}
    \end{figure}
  \end{columns}

\end{frame}

\section{Conclusion}
\begin{frame}{Conclusion}
\end{frame}

\begin{frame}{Potential PhD}
\end{frame}
%% \begin{document}
%% \title{Simple Beamer Class}
%% \author{Sascha Frank}
%% \date{\today}

%% \frame{\titlepage}

%% \frame{\frametitle{Table of contents}\tableofcontents}



\end{document}
